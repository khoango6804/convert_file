import os
import glob
import re
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import argparse

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)


def setup_folders():
    """Kh·ªüi t·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    folders = {
        "output_md": os.path.join(base_dir, "data", "output"),
        "output_txt": os.path.join(base_dir, "data", "txts"),  # ƒê·ªïi t√™n th∆∞ m·ª•c output
    }

    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
    for folder in folders.values():
        os.makedirs(folder, exist_ok=True)

    return folders


def clean_markdown(text):
    """L√†m s·∫°ch n·ªôi dung markdown ƒë·ªÉ chuy·ªÉn th√†nh text thu·∫ßn t√∫y"""
    # Lo·∫°i b·ªè c√°c header markdown (#, ##, ###)
    text = re.sub(r"^#+\s+", "", text, flags=re.MULTILINE)

    # Lo·∫°i b·ªè ƒë·ªãnh d·∫°ng in ƒë·∫≠m v√† in nghi√™ng
    text = re.sub(r"\*\*(.*?)\*\*", r"\1", text)
    text = re.sub(r"\*(.*?)\*", r"\1", text)
    text = re.sub(r"__(.*?)__", r"\1", text)
    text = re.sub(r"_(.*?)_", r"\1", text)

    # Lo·∫°i b·ªè ƒë·ªãnh d·∫°ng code
    text = re.sub(r"`(.*?)`", r"\1", text)

    # X·ª≠ l√Ω code blocks
    text = re.sub(r"```(?:.*?)\n(.*?)```", r"\1", text, flags=re.DOTALL)

    # Lo·∫°i b·ªè ƒë·ªãnh d·∫°ng link [text](url)
    text = re.sub(r"\[(.*?)\]\(.*?\)", r"\1", text)

    # Lo·∫°i b·ªè d·∫•u > c·ªßa blockquote
    text = re.sub(r"^>\s+", "", text, flags=re.MULTILINE)

    # Lo·∫°i b·ªè ƒë·ªãnh d·∫°ng danh s√°ch
    text = re.sub(r"^\s*[\-\*]\s+", "‚Ä¢ ", text, flags=re.MULTILINE)
    text = re.sub(r"^\s*\d+\.\s+", "", text, flags=re.MULTILINE)

    # X√≥a c√°c k√≠ hi·ªáu markdown kh√°c
    text = re.sub(r"^\s*---\s*$", "", text, flags=re.MULTILINE)

    # X·ª≠ l√Ω c√°c b·∫£ng markdown
    lines = text.split("\n")
    result_lines = []
    in_table = False
    header_cells = []

    for line in lines:
        if "|" in line and ("-+-" in line or "---" in line or ":---" in line):
            in_table = True
            continue

        if in_table and "|" in line:
            # Chuy·ªÉn ƒë·ªïi h√†ng b·∫£ng th√†nh text ƒë∆°n gi·∫£n
            cells = [cell.strip() for cell in line.split("|")]
            cells = [cell for cell in cells if cell]  # Remove empty cells

            # N·∫øu ƒë√¢y l√† h√†ng ƒë·∫ßu ti√™n sau header, l∆∞u l·∫°i l√†m header
            if not header_cells:
                header_cells = cells.copy()
                result_lines.append(" | ".join(header_cells))
            else:
                result_lines.append(" | ".join(cells))
        else:
            if in_table:
                in_table = False
                header_cells = []
            result_lines.append(line)

    # K·∫øt h·ª£p l·∫°i c√°c d√≤ng v√† lo·∫°i b·ªè d√≤ng tr·ªëng li√™n ti·∫øp
    text = "\n".join(result_lines)
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


def convert_file(input_file, output_folder):
    """Chuy·ªÉn ƒë·ªïi m·ªôt file markdown sang text"""
    try:
        filename = os.path.basename(input_file)
        name_without_ext = os.path.splitext(filename)[0]
        output_file = os.path.join(output_folder, f"{name_without_ext}.txt")

        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file ƒë·ªÉ x√°c ƒë·ªãnh ph∆∞∆°ng ph√°p x·ª≠ l√Ω
        file_size = os.path.getsize(input_file)

        if file_size > 10 * 1024 * 1024:  # > 10MB
            # X·ª≠ l√Ω file l·ªõn d√≤ng-theo-d√≤ng
            try:
                with (
                    open(input_file, "r", encoding="utf-8") as infile,
                    open(output_file, "w", encoding="utf-8") as outfile,
                ):
                    for chunk in read_in_chunks(infile):
                        cleaned_chunk = clean_markdown(chunk)
                        outfile.write(cleaned_chunk)

                return output_file, file_size, None
            except UnicodeDecodeError:
                # Th·ª≠ l·∫°i v·ªõi encoding kh√°c
                with (
                    open(input_file, "r", encoding="latin-1") as infile,
                    open(output_file, "w", encoding="utf-8") as outfile,
                ):
                    for chunk in read_in_chunks(infile):
                        cleaned_chunk = clean_markdown(chunk)
                        outfile.write(cleaned_chunk)

                return output_file, file_size, None
        else:
            # X·ª≠ l√Ω file nh·ªè
            try:
                with open(input_file, "r", encoding="utf-8") as f:
                    content = f.read()
            except UnicodeDecodeError:
                # Th·ª≠ v·ªõi encoding kh√°c n·∫øu utf-8 th·∫•t b·∫°i
                with open(input_file, "r", encoding="latin-1") as f:
                    content = f.read()

            # L√†m s·∫°ch content
            cleaned_content = clean_markdown(content)

            # Ghi ra file text
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(cleaned_content)

            return output_file, len(cleaned_content), None
    except Exception as e:
        return None, 0, f"L·ªói x·ª≠ l√Ω file {os.path.basename(input_file)}: {str(e)}"


def read_in_chunks(file_object, chunk_size=1024):
    """ƒê·ªçc file theo t·ª´ng ƒëo·∫°n ƒë·ªÉ x·ª≠ l√Ω file l·ªõn hi·ªáu qu·∫£"""
    while True:
        data = file_object.read(chunk_size)
        if not data:
            break
        yield data


def get_optimal_worker_count():
    """X√°c ƒë·ªãnh s·ªë worker t·ªëi ∆∞u d·ª±a tr√™n c·∫•u h√¨nh h·ªá th·ªëng"""
    import multiprocessing

    # L·∫•y s·ªë CPU cores
    cpu_count = multiprocessing.cpu_count()

    # Ki·ªÉm tra RAM kh·∫£ d·ª•ng (n·∫øu tr√™n Windows)
    ram_gb = None
    try:
        if os.name == "nt":  # Windows
            import psutil

            ram_gb = psutil.virtual_memory().total / (1024**3)
    except ImportError:
        pass  # psutil kh√¥ng kh·∫£ d·ª•ng, b·ªè qua ki·ªÉm tra RAM

    # ƒê√¢y l√† t√°c v·ª• I/O-bound, n√™n c√≥ th·ªÉ d√πng nhi·ªÅu worker h∆°n s·ªë core
    if cpu_count <= 2:
        workers = 2  # √çt nh·∫•t 2 worker
    else:
        workers = cpu_count + 2  # Nhi·ªÅu h∆°n s·ªë core v√¨ ch·ªß y·∫øu l√† I/O

    # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n RAM (n·∫øu c√≥ th√¥ng tin)
    if ram_gb is not None and ram_gb < 4:  # M√°y c√≥ √≠t RAM
        workers = min(workers, 4)  # Gi·ªõi h·∫°n s·ªë worker

    return workers


def main():
    parser = argparse.ArgumentParser(
        description="Chuy·ªÉn ƒë·ªïi file MD sang TXT ri√™ng bi·ªát"
    )
    parser.add_argument(
        "--override", action="store_true", help="Ghi ƒë√® l√™n c√°c file TXT ƒë√£ t·ªìn t·∫°i"
    )
    args = parser.parse_args()

    start_time = time.time()
    folders = setup_folders()

    # L·∫•y danh s√°ch file markdown
    md_files = glob.glob(os.path.join(folders["output_md"], "*.md"))

    if not md_files:
        logging.warning("‚ùå Kh√¥ng t√¨m th·∫•y file markdown n√†o trong th∆∞ m·ª•c output!")
        return

    logging.info(f"üîç T√¨m th·∫•y {len(md_files)} file markdown c·∫ßn chuy·ªÉn ƒë·ªïi")

    # L·ªçc c√°c file ƒë√£ t·ªìn t·∫°i (tr·ª´ khi c√≥ flag override)
    if not args.override:
        original_count = len(md_files)
        md_files = [
            f
            for f in md_files
            if not os.path.exists(
                os.path.join(
                    folders["output_txt"],
                    os.path.splitext(os.path.basename(f))[0] + ".txt",
                )
            )
        ]
        skipped = original_count - len(md_files)
        if skipped > 0:
            logging.info(
                f"‚è© B·ªè qua {skipped} file ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi tr∆∞·ªõc ƒë√≥ (s·ª≠ d·ª•ng --override ƒë·ªÉ ghi ƒë√®)"
            )

    if not md_files:
        logging.info("‚úÖ T·∫•t c·∫£ c√°c file ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi tr∆∞·ªõc ƒë√≥!")
        return

    # X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng worker t·ªëi ∆∞u
    worker_count = get_optimal_worker_count()
    logging.info(f"üñ•Ô∏è S·ª≠ d·ª•ng {worker_count} worker threads")

    # Kh·ªüi t·∫°o thanh ti·∫øn ƒë·ªô
    successful_files = 0
    failed_files = 0
    total_chars = 0

    # X·ª≠ l√Ω ƒëa lu·ªìng v·ªõi ThreadPoolExecutor
    with ThreadPoolExecutor(max_workers=worker_count) as executor:
        # T·∫°o c√°c futures cho m·ªói file c·∫ßn x·ª≠ l√Ω
        futures = {
            executor.submit(convert_file, md_file, folders["output_txt"]): md_file
            for md_file in md_files
        }

        # S·ª≠ d·ª•ng tqdm ƒë·ªÉ hi·ªÉn th·ªã ti·∫øn ƒë·ªô
        with tqdm(
            total=len(md_files), desc="Chuy·ªÉn ƒë·ªïi file", unit="file"
        ) as progress_bar:
            for future in as_completed(futures):
                md_file = futures[future]
                try:
                    result, chars, error = future.result()
                    if result:
                        successful_files += 1
                        total_chars += chars
                        progress_bar.set_postfix(
                            success=f"{successful_files}/{successful_files + failed_files}"
                        )
                    else:
                        failed_files += 1
                        logging.error(error)
                except Exception as e:
                    failed_files += 1
                    logging.error(f"‚ùå L·ªói x·ª≠ l√Ω {os.path.basename(md_file)}: {str(e)}")
                finally:
                    progress_bar.update(1)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    elapsed_time = time.time() - start_time
    logging.info(
        f"‚úÖ Chuy·ªÉn ƒë·ªïi ho√†n t·∫•t: {successful_files} th√†nh c√¥ng, {failed_files} th·∫•t b·∫°i"
    )
    logging.info(f"üìä T·ªïng s·ªë k√Ω t·ª± ƒë√£ x·ª≠ l√Ω: {total_chars:,}")
    logging.info(f"‚è±Ô∏è Th·ªùi gian th·ª±c hi·ªán: {elapsed_time:.2f} gi√¢y")
    logging.info(f"üìÅ C√°c file txt ƒë√£ ƒë∆∞·ª£c l∆∞u trong: {folders['output_txt']}")


if __name__ == "__main__":
    main()
