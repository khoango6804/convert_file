import os
import glob
import argparse
import logging
import time
from datasets import Dataset, Features, Value
from huggingface_hub import HfApi, login
from tqdm import tqdm

# Thiáº¿t láº­p logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)


def setup_paths():
    """Thiáº¿t láº­p cÃ¡c Ä‘Æ°á»ng dáº«n cáº§n thiáº¿t"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    txts_dir = os.path.join(base_dir, "data", "txts")

    if not os.path.exists(txts_dir):
        raise ValueError(f"ThÆ° má»¥c {txts_dir} khÃ´ng tá»“n táº¡i!")

    return txts_dir


def authenticate(token=None):
    """ÄÄƒng nháº­p vÃ o HuggingFace Hub"""
    if token is None:
        # Kiá»ƒm tra token trong biáº¿n mÃ´i trÆ°á»ng
        token = os.environ.get("HF_TOKEN")

    if not token:
        # Náº¿u khÃ´ng cÃ³ token, yÃªu cáº§u ngÆ°á»i dÃ¹ng nháº­p
        token = input("Nháº­p HuggingFace API Token cá»§a báº¡n: ").strip()

    try:
        login(token=token)
        logging.info("âœ… ÄÄƒng nháº­p HuggingFace thÃ nh cÃ´ng!")
        return token
    except Exception as e:
        raise ValueError(f"ÄÄƒng nháº­p tháº¥t báº¡i: {str(e)}")


def read_text_files(txts_dir):
    """Äá»c táº¥t cáº£ file txt vÃ  chuáº©n bá»‹ dataset"""
    text_files = glob.glob(os.path.join(txts_dir, "*.txt"))
    if not text_files:
        raise ValueError(f"KhÃ´ng tÃ¬m tháº¥y file txt nÃ o trong {txts_dir}")

    logging.info(f"ğŸ” ÄÃ£ tÃ¬m tháº¥y {len(text_files)} file txt")

    documents = []
    file_names = []
    file_sizes = []

    # Äá»c tá»«ng file vá»›i thanh tiáº¿n Ä‘á»™
    for txt_file in tqdm(text_files, desc="Äá»c file", unit="file"):
        try:
            file_name = os.path.basename(txt_file)
            file_size = os.path.getsize(txt_file)

            with open(txt_file, "r", encoding="utf-8") as f:
                text = f.read()

            documents.append(text)
            file_names.append(file_name)
            file_sizes.append(file_size)

        except Exception as e:
            logging.warning(f"âš ï¸ KhÃ´ng thá»ƒ Ä‘á»c file {txt_file}: {str(e)}")

    # Táº¡o dataset tá»« cÃ¡c tÃ i liá»‡u Ä‘Ã£ Ä‘á»c
    dataset_dict = {
        "text": documents,
        "file_name": file_names,
        "file_size": file_sizes,
    }

    return dataset_dict


def create_and_push_dataset(dataset_dict, repo_name, token):
    """Táº¡o dataset vÃ  Ä‘áº©y lÃªn HuggingFace Hub"""
    try:
        # Táº¡o dataset tá»« dict
        features = Features(
            {
                "text": Value("string"),
                "file_name": Value("string"),
                "file_size": Value("int64"),
            }
        )

        dataset = Dataset.from_dict(dataset_dict, features=features)
        logging.info(f"âœ… ÄÃ£ táº¡o dataset vá»›i {len(dataset)} máº«u")

        # TÃ­nh kÃ­ch thÆ°á»›c tá»•ng cá»§a dataset
        total_size_bytes = sum(dataset_dict["file_size"])
        total_size_mb = total_size_bytes / (1024 * 1024)
        logging.info(f"ğŸ“Š Tá»•ng kÃ­ch thÆ°á»›c: {total_size_mb:.2f} MB")

        # Push lÃªn HuggingFace
        logging.info(f"ğŸ”„ Äang upload lÃªn {repo_name}...")

        # Push dataset lÃªn hub
        dataset.push_to_hub(
            repo_id=repo_name,
            token=token,
            private=True,  # Set to False náº¿u muá»‘n dataset cÃ´ng khai
        )

        logging.info(
            f"âœ… Upload thÃ nh cÃ´ng: https://huggingface.co/datasets/{repo_name}"
        )

        # ThÃªm thÃ´ng tin README.md
        api = HfApi()
        readme_content = f"""
        # Dataset: {repo_name}
        
        Dataset bao gá»“m {len(dataset)} tÃ i liá»‡u vÄƒn báº£n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i tá»« Ä‘á»‹nh dáº¡ng Markdown sang text thuáº§n tÃºy.
        
        ## ThÃ´ng tin:
        
        - Sá»‘ lÆ°á»£ng tÃ i liá»‡u: {len(dataset)}
        - Tá»•ng kÃ­ch thÆ°á»›c: {total_size_mb:.2f} MB
        - NgÃ y táº¡o: {time.strftime("%Y-%m-%d")}
        
        ## Cáº¥u trÃºc:
        
        ```python
        DatasetDict({{
            'train': Dataset({{
                features: ['text', 'file_name', 'file_size'],
                num_rows: {len(dataset)}
            }})
        }})
        ```
        
        ## Sá»­ dá»¥ng:
        
        ```python
        from datasets import load_dataset
        
        dataset = load_dataset("{repo_name}")
        for i, example in enumerate(dataset["train"]):
            print(f"Document {{i + 1}}:")
            print(example["text"][:500] + "...")  # Hiá»ƒn thá»‹ 500 kÃ½ tá»± Ä‘áº§u tiÃªn
            print("-" * 50)
        ```
        """

        api.upload_file(
            path_or_fileobj=readme_content.encode(),
            path_in_repo="README.md",
            repo_id=repo_name,
            repo_type="dataset",
            token=token,
        )

        return True

    except Exception as e:
        logging.error(f"âŒ Upload tháº¥t báº¡i: {str(e)}")
        return False


def main():
    """HÃ m chÃ­nh"""
    parser = argparse.ArgumentParser(
        description="Upload txt files lÃªn HuggingFace Datasets"
    )
    parser.add_argument(
        "--repo", type=str, help="TÃªn repository trÃªn HuggingFace (username/repo-name)"
    )
    parser.add_argument("--token", type=str, help="HuggingFace API Token")
    args = parser.parse_args()

    start_time = time.time()

    try:
        # Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n
        txts_dir = setup_paths()

        # XÃ¡c Ä‘á»‹nh tÃªn repository
        if not args.repo:
            default_name = f"legal-documents-{time.strftime('%Y%m%d')}"
            repo_name = (
                input(f"Nháº­p tÃªn repository (máº·c Ä‘á»‹nh: {default_name}): ").strip()
                or default_name
            )
        else:
            repo_name = args.repo

        # Äáº£m báº£o Ä‘á»‹nh dáº¡ng username/repo-name
        if "/" not in repo_name:
            username = input("Nháº­p username HuggingFace cá»§a báº¡n: ").strip()
            repo_name = f"{username}/{repo_name}"

        # XÃ¡c thá»±c
        token = authenticate(args.token)

        # Äá»c cÃ¡c file
        logging.info(f"ğŸ“‚ Äang Ä‘á»c file tá»« {txts_dir}")
        dataset_dict = read_text_files(txts_dir)

        # Táº¡o vÃ  Ä‘áº©y dataset
        success = create_and_push_dataset(dataset_dict, repo_name, token)

        # ThÃ´ng bÃ¡o káº¿t quáº£
        if success:
            elapsed_time = time.time() - start_time
            logging.info(f"â±ï¸ Tá»•ng thá»i gian: {elapsed_time:.2f} giÃ¢y")
            logging.info(
                f"ğŸ”— Dataset cÃ³ thá»ƒ truy cáº­p táº¡i: https://huggingface.co/datasets/{repo_name}"
            )
        else:
            logging.error("âŒ QuÃ¡ trÃ¬nh upload khÃ´ng thÃ nh cÃ´ng")

    except Exception as e:
        logging.error(f"âŒ Lá»—i: {str(e)}")


if __name__ == "__main__":
    main()
